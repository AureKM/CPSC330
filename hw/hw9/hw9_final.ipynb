{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33c5b0c-d0f1-40c0-b794-3b3471ac73d2",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 9: Communication\n",
    "\n",
    "**Due date: See the [Calendar](https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/blob/master/docs/calendar.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086914c2-5de1-414a-8770-23bef9f312d0",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe22cb5-f825-4dba-b5e3-3538f4afe703",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "**You may work on this homework in a group and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 4. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be5b2d-1854-4c63-bcc6-9b6258b7293a",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed594c68-91c3-45d9-baec-6ac38a02c971",
   "metadata": {},
   "source": [
    "## Exercise 1: Communication\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767926d-c17d-4a93-b59a-7242a4c76ff0",
   "metadata": {},
   "source": [
    "### 1.1 Blog post \n",
    "rubric={points:23}\n",
    "\n",
    "Write up your analysis from hw5 or any other assignment or your side project on machine learning in a \"blog post\" or report format. It's fine if you just write it here in this notebook. Alternatively, you can publish your blog post publicly and include a link here. (See exercise 4.3.) The target audience for your blog post is someone like yourself right before you took this course. They don't necessarily have ML knowledge, but they have a solid foundation in technical matters. The post should focus on explaining **your results and what you did** in a way that's understandable to such a person, **not** a lesson trying to teach someone about machine learning. Again: focus on the results and why they are interesting; avoid pedagogical content.\n",
    "\n",
    "Your post must include the following elements (not necessarily in this order):\n",
    "\n",
    "- Description of the problem/decision.\n",
    "- Description of the dataset (the raw data and/or some EDA).\n",
    "- Description of the model.\n",
    "- Description your results, both quantitatively and qualitatively. Make sure to refer to the original problem/decision.\n",
    "- A section on caveats, describing at least 3 reasons why your results might be incorrect, misleading, overconfident, or otherwise problematic. Make reference to your specific dataset, model, approach, etc. To check that your reasons are specific enough, make sure they would not make sense, if left unchanged, to most students' submissions; for example, do not just say \"overfitting\" without explaining why you might be worried about overfitting in your specific case.\n",
    "- At least 3 visualizations. These visualizations must be embedded/interwoven into the text, not pasted at the end. The text must refer directly to each visualization. For example \"as shown below\" or \"the figure demonstrates\" or \"take a look at Figure 1\", etc. It is **not** sufficient to put a visualization in without referring to it directly.\n",
    "\n",
    "A reasonable length for your entire post would be **800 words**. The maximum allowed is **1000 words**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169eefb-18a8-4e13-b7ca-1b3539a79215",
   "metadata": {},
   "source": [
    "#### Example blog posts\n",
    "\n",
    "Here are some examples of applied ML blog posts that you may find useful as inspiration. The target audiences of these posts aren't necessarily the same as yours, and these posts are longer than yours, but they are well-structured and engaging. You are **not required to read these** posts as part of this assignment - they are here only as examples if you'd find that useful.\n",
    "\n",
    "From the UBC Master of Data Science blog, written by a past student:\n",
    "\n",
    "- https://ubc-mds.github.io/2019-07-26-predicting-customer-probabilities/\n",
    "\n",
    "This next one uses R instead of Python, but that might be good in a way, as you can see what it's like for a reader that doesn't understand the code itself (the target audience for your post here):\n",
    "\n",
    "- https://rpubs.com/RosieB/taylorswiftlyricanalysis\n",
    "\n",
    "Finally, here are a couple interviews with winners from Kaggle competitions. The format isn't quite the same as a blog post, but you might find them interesting/relevant:\n",
    "\n",
    "- https://medium.com/kaggle-blog/instacart-market-basket-analysis-feda2700cded\n",
    "- https://medium.com/kaggle-blog/winner-interview-with-shivam-bansal-data-science-for-good-challenge-city-of-los-angeles-3294c0ed1fb2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfdd094-eeb6-4f00-a3bc-5a6105eedb12",
   "metadata": {},
   "source": [
    "#### A note on plagiarism\n",
    "\n",
    "You may **NOT** include text or visualizations that were not written/created by you. If you are in any doubt as to what constitutes plagiarism, please just ask. For more information see the [UBC Academic Misconduct policies](http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,54,111,959). Please don't copy this from somewhere üôè. If you can't do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bfb58-802f-40e4-a597-4fe5e7bd3007",
   "metadata": {},
   "source": [
    "## Who will default? Using Machine Learning to predict if someone will default on their credit card bill\n",
    "\n",
    "### Project Background and the Dataset:\n",
    "\n",
    "Economists have long described the modern economy as credit-based, and today, credit extension plays a central role in the interactions between individuals, corporations, and financial institutions. To mitigate the risks associated with this activity, lenders attempt to predict default risk.\n",
    "\n",
    "In this project, we create this type of analysis. Using the Default of [Credit Card Clients Dataset](https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset), we build a prediction model for determining whether a user will default on their credit card bill. The dataset includes data from  Taiwan, collected between April to September 2005. It includes 24 columns.\n",
    "\n",
    "### Building the model\n",
    "\n",
    "**Data Wrangling:** We define the variable \"default.payment.next.month\" as the target variable and split the data using a 30% test size. \n",
    "\n",
    "**Exploratory Data Analysis (EDA):** This step allows us to uncover many characteristics of the dataset. \n",
    "1. No features have missing values. \n",
    "2. There are 21000 examples and no duplicate examples in the train set. \n",
    "3. In the target, 0 (no default) is almost 3x more likely than 1 (default). \n",
    "4. The marriage feature is a categorical feature, and the small proportion in values 0 and 3 can be ignored.\n",
    "\n",
    "**Feature engineering:** Using EDA, we are able to find out information about all 24 features/columns. The features are of different types and have data of various range, so it is important to do feature engineering before we can build models to analyze the data. \n",
    "\n",
    "So for the 24 features in this project, we separate them into numeric, categorical, drop and remainder. Next, we create a column transformer for scaling the numeric features and an OneHotEncoder for the categorical feature. Using a column transformer, we are able to easily apply different transformation to the 4 types of columns that we identified. \n",
    "- Numeric features: this dataset have numerous numeric features, such as 'LIMIT_BAL', 'AGE', 'BILL_AMT1', but the good thing is that none of these columns have missing values. So it is sufficient to use a StandardScaler to process this type of data.\n",
    "\n",
    "- Categorical features: ‚ÄòMARRIAGE‚Äô is the only categorical feature we defined in this dataset. There are 3 values for marriage, 1=married, 2=single, 3=others. We decide to use an OneHotEncoder to separate it into 3 columns.\n",
    "\n",
    "- Drop features: upon EDA, we decide to drop the column ‚ÄòID‚Äô. Because we are trying to target the default payment next month for each person in this project, ‚ÄòID‚Äô is not an important feature for us to consider. \n",
    "\n",
    "- Remainder features: other than the above mentioned features, we still have 8 columns remaining. \n",
    "\n",
    "**Baseline model:**\n",
    "We create a baseline model using a DummyClassifier for comparing results.  DummyClassifier makes predictions without considering the input feature values, therefore, makes it a great baseline model for us to compare with other complex models that we later choose to use.\n",
    "\n",
    "**Creating the Models:**\n",
    "\n",
    "- Linear model\n",
    "\n",
    "First, we create a logistic regression model, which assigns probabilities to the outcomes using the Sigmoid function. \n",
    "\n",
    "- Random forest\n",
    "\n",
    "Instead of a single DecisionTree model, we decide to use a RandomForest model, which subdivides the dataset and creates decision trees. Since RandomForest takes average of the output of multiple decision trees, and it choose trees randomly, we believe it is a good candidate for our problem. \n",
    "\n",
    "- Catboost\n",
    "\n",
    "Third, we create a Catboost model, which uses oblivious decision trees ( same splitting criterion across the level of the tree). Catboost is a gradient boosted trees model. Based on the examples we seen on lectures, it gives the best results compared to other gradient boosted trees models, so we decide to try Catboost. \n",
    "\n",
    "- Knn\n",
    "\n",
    "Finally, we create a KNN model, which uses proximity to make the prediction. We then use the result from hyperparameter optimization to choose the best k for this model, which is 51. \n",
    "\n",
    "The results indicate that logistic regression has the fastest fit time. However, the other 3 models have significantly better test scores.\n",
    "\n",
    "\n",
    "**Results:**\n",
    "After we trained data with several models, we found that the Catboost model had the best performance. We could find the best depth and n_estimator for our catboost model through hyperparameter optimization. Ultimately, our model achieves a test score of 0.820 with a training score of 0.829. The score looks good that there is no overfitting or underfitting, and the gap between the test score and the training score is small, because we choose accuracy as the metric for assessment. However, we may be overconfident with our results. We don't have enough time to try and optimize other hyperparameters for the catboost model, and we may find an even better-performing model after optimizing different hyperparameters. We didn't try stacking and averaging on the models above to improve our model performance, and we didn't try models such as decision tree and SVM, so we can't know if we can find a better performing model. Although accuracy is a good metric, we should also try other measures, such as the Brier score, to measure a different aspect of model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052395d-a695-4063-97b6-46c4e13016d8",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59667c9-db6a-4c12-a556-5b9815ef3564",
   "metadata": {},
   "source": [
    "### 1.2 Effective communication technique\n",
    "rubric={points:4}\n",
    "\n",
    "Describe one effective communication technique that you used in your post, or an aspect of the post that you are particularly satisfied with. (Max 3 sentences.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae108e-5892-4f79-9560-7b9fb6b17be6",
   "metadata": {},
   "source": [
    "We explained the ideas in chunks which follow the flow of the project and have clear titles to signify each step. As the target audience is someone right before taking this course and the word limit, we chose to not go into much depth of explaining each models but briefly go through them and focus more on the purpose of the project as well as the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea9c37-34c9-4b3e-a2df-e00cedd3e8ae",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56965b8c-9f4d-4a68-be4c-2a745dcf9989",
   "metadata": {},
   "source": [
    "### (optional, not for marks) 1.3\n",
    "\n",
    "Publish your blog post from 1.1 publicly using a tool like Hugo, or somewhere like medium.com, and paste a link here. Be sure to pick a tool in which code and code output look reasonable. This link could be a useful line on your resume!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a55e63-38cb-4e36-867f-0261d1c583de",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cefc8e-cf76-4c27-9aa6-c560cbc0fc2b",
   "metadata": {},
   "source": [
    "## Exercise 2: Your takeaway from the course \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What is your biggest takeaway from this course? \n",
    "\n",
    "> Please write thoughtful answers. I'm looking forward to read your answers üôÇ. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b870e-96a4-4997-b9f8-3d5f6fde4670",
   "metadata": {},
   "source": [
    "Throughout the course, we were given a lot of tools to deal with different tasks and data sets. My biggest takeaway from the course is that now I know which tools are available to me out there to use when I face a new tasks. Even though we did not go in depth to understand each individual code or each of the tools we used but we‚Äôve gained an understanding of how to make each of them work and apply them in our tasks. It‚Äôll take time to practice and get more familiar with the materials and I will have to revisit the codes as well as lectures again but now I have a better sense of what Machine Learning is as well as its power and applications. NLP is particularly interesting to me. Its applications can be seen everywhere around us now, but only after this course do I really get to know what it is and what have been developed in the field. Working with words and sentences previously seemed very challenging to me even just to imagine, but after seeing what ave been done in the field, it broadens my knowledge of what could potentially be done and utitlized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb9e2f-a2d2-4f56-9fb4-c91492e4801b",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214c2aa-790d-4c80-a784-8f1135ab9e66",
   "metadata": {},
   "source": [
    "**PLEASE READ BEFORE YOU SUBMIT:** \n",
    "\n",
    "When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from \"1\" will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "4. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e160c-d947-4123-8e67-fa3c89c9aa8f",
   "metadata": {},
   "source": [
    "### Congratulations üëèüëè\n",
    "\n",
    "That's all for the assignments! Congratulations on finishing all homework assignments! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f3bee4-0171-4465-838f-e5ac8a943e10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'eva-congrats.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/display.py:1032\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/formatters.py:973\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    970\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 973\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/display.py:1022\u001b[0m, in \u001b[0;36mImage._repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m   1021\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mimetype\n\u001b[0;32m-> 1022\u001b[0m     data, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43malways_both\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[1;32m   1024\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {mimetype: metadata}\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/display.py:1034\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: 'eva-congrats.png'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'eva-congrats.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/display.py:1032\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    341\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/display.py:1054\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FMT_PNG:\n\u001b[0;32m-> 1054\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/display.py:1034\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: 'eva-congrats.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"eva-congrats.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85638f81-8cba-4bcd-adf7-68b3b9d0862c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
